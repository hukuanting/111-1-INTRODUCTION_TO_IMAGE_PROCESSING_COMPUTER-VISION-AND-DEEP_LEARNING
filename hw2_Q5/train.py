# -*- coding: utf-8 -*-
"""Resnet 50 .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Js_s8OWeBXk0RbkgDTuxfh1b_DB83Qe6
"""

import numpy as np
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import Dense, Flatten, AveragePooling2D, Dropout, Conv2D, Activation, MaxPool2D,GlobalAveragePooling2D
from tensorflow.keras.models import Model
from tensorflow.keras.applications.resnet import ResNet50
from tensorflow.keras.applications.inception_v3 import InceptionV3
from tensorflow.keras.applications.xception import Xception
from tensorflow.keras import layers
from tensorflow.keras.models import *
from tensorflow.keras.layers import *
from tensorflow.keras.applications import *
from tensorflow.keras.preprocessing.image import *
import h5py
import numpy as np
from sklearn.utils import shuffle
from tensorflow.keras.optimizers import Adam
import os
from sklearn.model_selection import train_test_split
import glob
from matplotlib import pyplot as plt
from tensorflow import keras
import cv2
from PIL import Image

# !unzip /content/drive/MyDrive/train.zip

train_dir = '/content/Dataset_OpenCvDl_Hw2_Q5/training_dataset'
validation_dir ='/content/Dataset_OpenCvDl_Hw2_Q5/validation_dataset'
cat_dir = '/content/Dataset_OpenCvDl_Hw2_Q5/training_dataset/Cat'
dog_dir = '/content/Dataset_OpenCvDl_Hw2_Q5/training_dataset/Dog'

'''for fname in os.listdir(cat_dir):
  n=str.split(fname,'.')[-1]
  print(n)
  if n!='jpg':
    print(fname)
print("---")
for fname in os.listdir(dog_dir):
  n=str.split(fname,'.')[-1]
  if n!='jpg':
    print(fname)
image_list=[]
label_list=[]

for fname in os.listdir(cat_dir):
  cat_img = cv2.imread(cat_dir+'/'+fname)
  cat_img = cv2.resize(cat_img, (224,224))  
  image_list.append(cat_img)
  label_list.append(0)

for fname in os.listdir(dog_dir):
  dog_img = cv2.imread(dog_dir+'/'+fname)   
  dog_img = cv2.resize(dog_img,(224, 224))
  image_list.append(dog_img)
  label_list.append(1)
for index in range(0,len(image_list)):
  if len(image_list[index][0][0])!=3:
    print(index)  
img_arr=np.array(image_list, dtype=np.float32) 
label_arr=np.array(label_list, dtype=np.int16)    
print(img_arr.shape[1])
print(label_arr.shape)
plt.imshow(img_arr[0])
plt.show()
x_train = np.reshape(img_arr, (-1, 1))
y_train = label_arr
print(x_train.shape)
print(y_train.shape)
from imblearn.over_sampling import SMOTE
x_train, y_train = SMOTE().fit_resample(x_train, y_train)'''

def augment(image):
  x = tf.cast(image, tf.float32)
  x = tf.image.resize(x, [224, 224])
  x = tf.image.random_crop(x, size=[180, 224, 3])
  x = tf.image.random_brightness(x, max_delta=0.5)
  x = tf.image.random_hue(x, 0.08)
  x = tf.image.random_saturation(x, 0.6, 1.6)
  x = tf.image.random_contrast(x, 0.7, 1.3)
  return x

index=0
for fname in os.listdir(cat_dir):
  index=index+1
  cat_img = cv2.imread(cat_dir+'/'+fname)
  if cat_img is None:
    print(fname)
    os.remove(cat_dir+'/'+fname)
  else:
    new_img = augment(cat_img)
    new_img=np.array(new_img)
    num=16200+index
    cv2.imwrite(cat_dir+'/'+str(num)+'.jpg', new_img)

for fname in os.listdir(dog_dir):
  dog_img = cv2.imread(dog_dir+'/'+fname)
  if dog_img is None:
    print(fname)
    os.remove(dog_dir+'/'+fname)
  else:
    pass

for fname in os.listdir("/content/Dataset_OpenCvDl_Hw2_Q5/validation_dataset/Cat"):
  cat_img = cv2.imread("/content/Dataset_OpenCvDl_Hw2_Q5/validation_dataset/Cat/"+fname)
  if cat_img is None:
    print(fname)
    os.remove("/content/Dataset_OpenCvDl_Hw2_Q5/validation_dataset/Cat/"+fname)
  else:
    pass
for fname in os.listdir("/content/Dataset_OpenCvDl_Hw2_Q5/validation_dataset/Dog"):
  dog_img = cv2.imread("/content/Dataset_OpenCvDl_Hw2_Q5/validation_dataset/Dog/"+fname)
  if dog_img is None:
    print(fname)
    os.remove("/content/Dataset_OpenCvDl_Hw2_Q5/validation_dataset/Dog/"+fname)
  else:
    pass

import os
count_cat = 0
count_dog = 0
for filename in os.listdir(cat_path): 
  count_cat = count_cat + 1
for filename in os.listdir(dog_path): 
  count_dog = count_dog + 1  
print(count_cat)
print(count_dog)

import numpy as np
import matplotlib.pyplot as plt

left = np.array(['cat', 'dog'])
height = np.array([count_cat, count_dog])
plt.bar(left, height)
for a,b in zip(left, height):
    plt.text(a, b, b, ha='center', va='bottom')
plt.show()

train_datagen = ImageDataGenerator(rescale = 1./255, 
                                   rotation_range=30, 
                                   width_shift_range=0.2, 
                                   height_shift_range=0.2, 
                                   shear_range=0.2, 
                                   zoom_range = 0.2, 
                                   horizontal_flip = True)

validation_datagen = ImageDataGenerator(rescale = 1./255)

training_set = train_datagen.flow_from_directory(train_dir,
                                                 target_size = (224, 224), 
                                                 batch_size = 16, 
                                                 class_mode = 'binary', 
                                                 shuffle=True)

validation_set = validation_datagen.flow_from_directory(validation_dir,
                                            	  target_size = (224, 224),
                                            	  batch_size = 16,
                                            	  class_mode = 'binary',
                                            	  shuffle = False)

base = tf.keras.applications.resnet50.ResNet50(input_shape=(224, 224, 3), weights='imagenet', include_top=False)
x = base.output
x = GlobalAveragePooling2D()(x)
output = Dense(1, activation='sigmoid')(x)
model = tf.keras.models.Model(inputs=base.input, outputs=output)

model.summary()

import tensorflow_addons as tfa
loss_function = tfa.losses.SigmoidFocalCrossEntropy(alpha=0.4, gamma=1.0)

model.compile(optimizer=Adam(learning_rate=0.0001), 
              loss=loss_function, 
              metrics=['accuracy'])

history = model.fit_generator(training_set, 
                    validation_data=validation_set ,
                    epochs=5)

acc_focal = history.history['accuracy'][-1]
acc_focal = round(acc_focal, 3)*100
print(acc_focal)

loss_function = tf.keras.losses.BinaryCrossentropy()

model.compile(optimizer=Adam(learning_rate=0.0001), 
              loss=loss_function, 
              metrics=['accuracy'])

history = model.fit_generator(training_set, 
                    validation_data=validation_set ,
                    epochs=5)

acc_binary = round(history.history['accuracy'][-1], 3)*100
print(acc_binary)

left = np.array(['Focal loss', 'Binary Cross Entropy'])
height = np.array([acc_focal, acc_binary])
plt.bar(left, height)
for a,b in zip(left, height):
    plt.text(a, b, b, ha='center', va='bottom')
plt.ylabel("Accuracy(%)")    
plt.show()

import cv2
from skimage.transform import resize
import matplotlib.pyplot as plt

im = plt.imread('/content/Dataset_OpenCvDl_Hw2_Q5/validation_dataset/Dog/10015.jpg')
res = resize(im, (224, 224))

plt.imshow(res)
plt.show() 
#x = np.expand_dims(x, axis=0)
x = np.reshape(res,[-1,224,224,3])/255.

result = model.predict(x)
print(result)
print('--------------')
if result > 0.5:
  print("dog")
else: 
  print("cat")

model.save('model.h5')

from google.colab import files

files.download('model.h5')

from google.colab import drive
drive.mount('/content/drive')