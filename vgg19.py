# -*- coding: utf-8 -*-
"""VGG19.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AO26lpVlW8HgqopUuFtItxVDTiCvGJaJ
"""

!pip install --upgrade tensorflow

# Keras, dataset, and VGG19 imports
import tensorflow
import keras
from keras.datasets import cifar10
from keras.applications import VGG19
from keras.models import Sequential
from keras.layers import Dense, Flatten, Dropout
import numpy as np
import cv2
import matplotlib.pyplot as plt
# Loading VGG19 with imagenet weights
from keras.layers import Input

vgg19_model = VGG19(include_top = True, weights='imagenet')
vgg19_model.summary()

# define new empty model
model = Sequential()

# add all layers except output from VGG19 to new model
for layer in vgg19_model.layers[:-1]:
  model.add(layer)

# freeze all weights
for layer in model.layers:
  layer.trainable = False

# add dropout layer and new output layer
model.add(Dense(1024, activation='ReLU'))
model.add(Dense(512, activation='ReLU'))
model.add(Dense(10, activation='softmax'))
model.summary()

# load dataset
(x_train, y_train) , (x_val, y_val) = cifar10.load_data()



NUM_CLASSES = 10

y_train = keras.utils.to_categorical(y_train, NUM_CLASSES)
y_val = keras.utils.to_categorical(y_val, NUM_CLASSES)

model.compile(optimizer="adam", loss="categorical_crossentropy", metrics=["accuracy"])

# returns batch_size random samples from either training set or validation set
# resizes each image to (224, 244, 3), the native input size for VGG19
def getBatch(batch_size, train_or_val='train'):
  x_batch = []
  y_batch = []
  if train_or_val == 'train':
    idx = np.random.randint(0, len(x_train), (batch_size))

    for i in idx:
      img = cv2.resize(x_train[i], (224, 224), interpolation=cv2.INTER_CUBIC)
      x_batch.append(img)
      y_batch.append(y_train[i])
  elif train_or_val == 'val':
    idx = np.random.randint(0, len(x_val), (batch_size))

    for i in idx:
      img = cv2.resize(x_val[i], (224, 224), interpolation=cv2.INTER_CUBIC)
      x_batch.append(img)
      y_batch.append(y_val[i])
  else:
    print("error, please specify train or val")

  x_batch = np.array(x_batch)
  y_batch = np.array(y_batch)
  return x_batch, y_batch

from tqdm import tqdm
import tensorflow.keras.backend as K

EPOCHS = 30
BATCH_SIZE = 250
VAL_SIZE = 500
STEPS  = 50

out_train_loss   = []
out_train_accuracy = []
out_val_loss    = []
out_val_accuracy  = []

for e in range(EPOCHS):
  train_loss = 0
  train_acc = 0


  for s in range(STEPS):
    x_batch, y_batch = getBatch(BATCH_SIZE, "train")

    out = model.train_on_batch(x_batch, y_batch)

    train_loss += out[0]
    train_acc  += out[1]

  print(f"Epoch: {e}\nTraining Loss = {train_loss / STEPS}\tTraining Acc = {train_acc / STEPS}")

  out_train_loss.append(train_loss/STEPS)
  out_train_accuracy.append(train_acc/STEPS)

  x_v, y_v = getBatch(VAL_SIZE, "val")
  eval = model.evaluate(x_v, y_v)

  print(f"Validation loss: {eval[0]}\tValidation Acc: {eval[1]}\n")

  out_val_loss.append(eval[0])
  out_val_accuracy.append(eval[1])

epochs_range = range(EPOCHS)

plt.figure(figsize=(16, 6))
plt.subplot(1, 2, 1)

plt.plot(epochs_range, out_train_accuracy, label='Training Accuracy')
plt.plot(epochs_range, out_val_accuracy, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(1, 2, 2)
plt.plot(epochs_range, out_train_loss, label='Training Loss')
plt.plot(epochs_range, out_val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()

model.save('my_model.h5')

CATEGORIES = "airplane automobile bird cat deer dog frog horse ship truck".split(" ")

x_v, y_v = getBatch(10, "val")

for i in range(1):
  plt.imshow(x_v[i])
  plt.show()
  print("pred: " +  CATEGORIES[np.argmax(model.predict(x_v[i:i+1]))])
  print("acct: " + CATEGORIES[np.argmax(y_v[i])])